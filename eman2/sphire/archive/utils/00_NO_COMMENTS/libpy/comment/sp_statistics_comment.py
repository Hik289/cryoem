






























































































































































































































































































































































































































































































































































































































'''0
def ave_var_series(data, kb):
	"""
		Calculate average and variance of an image series using current alignment parameters
	"""
	from sp_fundamentals import rotshift2dg
	from sp_utilities    import model_blank
	n = len(data)
	nx = data[0].get_xsize()
	ny = data[0].get_ysize()
	ave = model_blank(nx,ny)
	var = model_blank(nx,ny)
	for i in xrange(n):
		alpha = data[i].get_attr('alpha')
		sx    =  data[i].get_attr('sx')
		sy    =  data[i].get_attr('sy')
		mirror =  data[i].get_attr('mirror')
		temp = rotshift2dg(data[i], alpha, sx, sy, kb)
		if  mirror: temp.process_inplace("xform.mirror",{"axis":'x'})
		Util.add_img(ave, temp)
		Util.add_img2(var, temp)

	ave /= n
	return ave, (var - ave*ave*n)/(n-1)

def ave_var_series_g(data, kb):
	"""
		Calculate average and variance of a image series using current alignment parameters,
		data contains images prepared for gridding
	"""
	from sp_fundamentals import rtshgkb
	from sp_utilities    import model_blank
	n = len(data)
	ny = data[0].get_ysize()/2
	nx = ny
	ave = model_blank(nx,ny)
	var = model_blank(nx,ny)
	for i in xrange(n):
		alpha = data[i].get_attr('alpha')
		sx =  data[i].get_attr('sx')
		sy =  data[i].get_attr('sy')
		mirror =  data[i].get_attr('mirror')
		temp = rtshgkb(data[i], alpha, sx, sy, kb)
		if  mirror: temp.process_inplace("xform.mirror",{"axis":'x'})
		Util.add_img(ave, temp)
		Util.add_img2(var, temp)

	ave /= n
	return ave, (var - ave*ave*n)/(n-1)
	
def ave_oe_series_g(data, kb):
	"""
		Calculate odd and even averages of a image series using current alignment parameters,
		      data contains images prepared for gridding
	"""
	from sp_fundamentals import rtshgkb
	from sp_utilities    import model_blank
	n  = len(data)
	ny = data[0].get_ysize()/2
	nx = ny
	ave1 = model_blank(nx, ny)
	ave2 = model_blank(nx, ny)
	for i in xrange(n):
		alpha  =  data[i].get_attr('alpha')
		sx     =  data[i].get_attr('sx')
		sy     =  data[i].get_attr('sy')
		mirror =  data[i].get_attr('mirror')
		temp = rtshgkb(data[i], alpha, sx, sy, kb)
		if  mirror: temp.process_inplace("xform.mirror", {"axis":'x'})
		if i%2 == 0: Util.add_img(ave1, temp)
		else:        Util.add_img(ave2, temp)
	ave1 /= (n/2+(n%2))
	ave2 /= (n/2)
	return ave1, ave2
'''

























































































































































































































































'''1
#  Not used anywhere.
def add_series_class_ctf(images, ctf1, ctf2, snr, assign, kc):
	""" Calculate average and variance files for each group in an image series
		taking into account CTF information

	Usage:  average,variance = add_series(images, assign, kc)
		images   - list of images
		assign - list of group assignments
		kc     - number of groups

	  average and variance are output objects
	  
	"""
	from sp_fundamentals import  fftip, fft
	from sp_filter       import  filt_table
	from sp_utilities    import  model_blank #, info
	nx = images[0].get_xsize()
	ny = images[0].get_ysize()
	nz = images[0].get_zsize()
	ave = []
	var = []
	tota = model_blank(nx - 2 + images[0].get_attr('is_fftodd'), ny, nz)
	for k in range(kc):
		var.append(tota.copy())   # these are real!
	fftip(tota)
	for k in range(kc):
		ave.append(tota.copy())   # Fourier
	
	nclass = [0]*kc
	lctf = len(ctf2[0])
	ctf_2 = [[0.0]*lctf for k in range(kc)]

	# First the averages
	for im in range(len(images)):
		ctf_x = filt_table( images[im], ctf1[im] )
		k = assign[im]
		Util.add_img(ave[k], ctf_x)
		#Cls[k].C += ctf_x
		nclass[k] += 1
		for i in range(lctf): ctf_2[k][i] += ctf2[im][i]

	# and the total average
	tcft2 = [0.0]*lctf
	for k in range(kc):
		Util.add_img(tota, ave[k])
		for i in range(lctf): tcft2[i] += ctf_2[k][i]
	for i in range(lctf):  tcft2[i] = 1.0/(tcft2[i] + 1.0/snr)
	tota = filt_table( tota, tcft2 )

	for k in range(kc):
		for i in range(lctf):  ctf_2[k][i] = 1.0/(ctf_2[k][i] + 1.0/snr)
		ave[k] = filt_table( ave[k], ctf_2[k] )

	# Variance files have to be in real space - nobody wants to look at them in Fourier space!
	
	totv = model_blank(nx - 2 + images[0].get_attr('is_fftodd'), ny, nz) 
	for im in range(len(images)):
		# so we have to compute inverse FTs of all images
		fim = fft(images[im])
		#  first total variance
		temp = fft( filt_table( tota, ctf1[im] ) )
		temp = Util.subn_img( fim, temp)  # in real space now!
		Util.add_img2(totv, temp)
	
		# now variance images for each group
		k = assign[im]
		temp = fft( filt_table( ave[k], ctf1[im] ) )
		temp = Util.subn_img( fim, temp)  # in real space now!
		Util.add_img2(var[k], temp)

	Util.mul_scalar(totv, 1.0/float(len(images)-1))

	for k in range(kc):
		if(nclass[k] > 1):
			Util.mul_scalar(var[k], 1.0/float(nclass[k]-1))
		else:
			var[k].to_zero()

	# finally compute inverse FFT of averages
	for k in range(kc):
		ave[k] = fft(ave[k])

	return fft(tota), totv, ave, var, nclass
'''

























































































































'''2
		oc = filt_ctf(ave, ctf_params, dopad=False)
		Util.sub_img(ima, Util.window(fft(oc),nx,ny,1,0,0,0))  # no windowing necessary?
		'''





























































































































































































































"""3
	Util.mul_scalar(var, 1.0/float(n-1))
	Util.mul_img(ave, ave)
	ave *= n
	"""
"""4
	Util.mul_img(sumsq, sumsq)
	#sumsq  = fft(window2d(fft(sumsq),nx,ny))

	#Util.div_filter(sumsq, ctf_2_sum)
	#Util.sub_img(var, sumsq)
	#Util.mul_scalar(var, 1.0/float(n-1))
	#Util.div_filter(sumsq, ctf_2_sum)

	#Util.mul_img(ave, ave)

	#Util.mul_img(ave, ctf_2_sum)
	#Util.mul_img(ave, ctf_2_sum)
	#ave *= n
	#var /= (n-1)

	nn = nx2//2
	nm = ny2//2

	from sp_utilities import info
	from sp_fundamentals import resample
	sumsq = Util.pack_complex_to_real(sumsq)
	sumsq[nn,nm] = sumsq[nn+1,nm]
	#if dopa:  sumsq = resample(sumsq,0.5)
	#info(var,None, "   tvar in ssnr2d")
	tvar = Util.divn_filter(var, ctf_2_sum)
	#info(tvar,None, "   tvar in ssnr2d first div")
	Util.div_filter(tvar, ctf_2_sum)
	#info(tvar,None, "   tvar in ssnr2d second div")
	tvar =  Util.pack_complex_to_real(tvar)
	#info(tvar,None, "   tvar in ssnr2d pack")
	tvar[nn,nm] = tvar[nn+1,nm]
	#if dopa:  tvar  = resample(tvar,0.5)
	#info(tvar,None, "   tvar in ssnr2d after resample")


	var = Util.pack_complex_to_real(var)
	var[nn,nm] = var[nn+1,nm]
	#info(var,None, "   var in ssnr2d")
	#if dopa:  var  = resample(var,0.5)
	#info(var,None, "   var in ssnr2d after resample")
	ssnr = sumsq/var - 1.0
	rave = rot_avg_table(sumsq)
	rvar = rot_avg_table(var)

	rssnr = []
	for i in range(len(rvar)):
		if rvar[i] > 0.0: qt = max(0.0, rave[i]/rvar[i] - 1.0)
		else:              ERROR("ssnr2d","rvar negative",1)
		rssnr.append(qt)
	return rssnr, rave, rvar, ssnr, sumsq, ave, tvar
	"""

'''5
def ssnr2d_ctf_OLD(data, mask = None, mode=""):
	"""
	Calculate ssnr and variance in Fourier space for 2D images including CTF information
	If mode = "a" apply alignment parameters
	"""
	from sp_fundamentals import fft, fftip, rot_shift2D, rot_avg_table
	from sp_morphology   import ctf_img, threshold
	from sp_filter       import filt_ctf
	from sp_utilities    import get_params2D
	import  types
	
	if type(data) is bytes:
		n = EMUtil.get_image_count(data)
		ima = EMData()
		ima.read_image(data, 0, True)
		if ima.get_attr_default('ctf_applied', 1) == 1:
			ERROR("data cannot be ctf-applied","ssnr2d",1)
		nx = ima.get_xsize()
		ny = ima.get_ysize()
		nz = ima.get_zsize()
	else:
		if data[0].get_attr_default('ctf_applied', 1) == 1:
			ERROR("data cannot be ctf-applied","ssnr2d",1)
		n = len(data)
		nx = data[0].get_xsize()
		ny = data[0].get_ysize()
		nz = data[0].get_zsize()

	ctf_2_sum = EMData(nx, ny, nz, False)
	sumsq     = EMData(nx, ny, nz, False)
	var       = EMData(nx, ny, nz, False)

	for i in range(n):
		if type(data) is bytes:
			ima = EMData()
			ima.read_image(data, i)
		else:
			ima = data[i].copy()
		ctf_params = ima.get_attr('ctf')
		if mode == "a":
			alpha, sx, sy, mirror, scale = get_params2D(ima)
			ima = rot_shift2D(ima, alpha, sx, sy, mirror)
			ctf_params.dfang += alpha
			if mirror == 1:  ctf_params.dfang = 270.0-ctf_params.dfang
		if mask:  Util.mul_img(ima, mask)
		fftip(ima)
		oc = filt_ctf(ima, ctf_params)
		Util.add_img(sumsq, oc)
		Util.add_img2(var, ima)
		Util.add_img2(ctf_2_sum, ctf_img(nx, ctf_params, ny=ny))
	Util.mul_img(sumsq, sumsq)
	Util.div_filter(sumsq, ctf_2_sum)
	Util.sub_img(var, sumsq)
	Util.mul_scalar(var, 1.0/float(n-1))
	Util.div_filter(sumsq, ctf_2_sum)

	var   = Util.pack_complex_to_real(var)
	sumsq = Util.pack_complex_to_real(sumsq)
	sumsq *= n
	ssnr   = sumsq/var - 1.0
	rvar = rot_avg_table(var)
	rsumsq = rot_avg_table(sumsq)
	rssnr = []
	for i in range(len(rvar)):
		if rvar[i] > 0.0: qt = max(0.0, rsumsq[i]/rvar[i] - 1.0)
		else:              ERROR("ssnr2d","rvar negative",1)
		rssnr.append(qt)
	return rssnr, rsumsq, rvar, ssnr, sumsq, var
'''

























































































































































































































































































































































































































































































































































































"""6
				for x in xrange(nx):
					for y in xrange(ny):
						for z in xrange(nz):
							if(m.get_value_at(x,y,z) > 0.5):
								if(freqvol.get_value_at(x,y,z) == 0.0):
									if(tmp3.get_value_at(x,y,z) < cutoff):
										freqvol.set_value_at(x,y,z,freq)
										bailout = 0
									else:
										if(k == number_of_proc-1):
											bailout = 0
				"""
"""7
			if res_overall !=-1.0:
				t = res_overall- Util.infomask(freqvol, m, True)[0]
				print t
				freqvol += t
			"""





















































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































'''if myid == main_node:8
		je_return = [0.0]*(ncpu)
		for n1 in xrange(ncpu):
			if n1 != main_node: je_return[n1]	=	mpi_recv(1,MPI_FLOAT, n1, SPARX_MPI_TAG_UNIVERSAL, MPI_COMM_WORLD)
 			else:               je_return[main_node]  = Je
	else:
		mpi_send(Je, 1, MPI_FLOAT, main_node, SPARX_MPI_TAG_UNIVERSAL, MPI_COMM_WORLD)'''












































'''if myid == main_node:9
		for n in xrange( ncpu ):
			print " n==", n, "Cls['n'] after ==", (r_cls[ n ])['n']	'''























































































































































































































































































































































































































'''if trials > 1:10
		if ALL_EMPTY:
			#print_msg('>>> WARNING: All trials resulted in empty clusters, STOP k-means.\n\n')
			sys.exit()

	# if severals trials choose the best
	if trials > 1:
		val_min = 1.0e20
		best    = -1
		for n in xrange(trials):
			if MemJe[n] < val_min:
				val_min = MemJe[n]
				best    = n
		# affect the best
		Cls    = MemCls[best]
		Je     = MemJe[best]
		assign = MemAssign[best]'''





























































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































'''11
-- Munkres algorithm (or Hungarian algorithm) ----------------------------------

Copyright and License
=====================

Copyright (c) 2008 Brian M. Clapper

This is free software, released under the following BSD-like license:

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:

  1. Redistributions of source code must retain the above copyright notice,
     this list of conditions and the following disclaimer.

  2. The end-user documentation included with the redistribution, if any,
     must include the following acknowlegement:

     This product includes software developed by Brian M. Clapper
     (bmc@clapper.org, http://www.clapper.org/bmc/). That software is
     copyright (c) 2008 Brian M. Clapper.

     Alternately, this acknowlegement may appear in the software itself, if
     and wherever such third-party acknowlegements normally appear.

THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESSED OR IMPLIED
WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO
EVENT SHALL BRIAN M. CLAPPER BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. 


'''


























































































































































































































































































































































'''12
# Hungarian algorithm between two partitions
def Hungarian(part1, part2):
	from sp_statistics import Munkres
	from numpy      import zeros, array
	import sys

	K = len(part1)
	# prepare matrix
	MAT = [[0] * K for i in xrange(K)]
	for k1 in xrange(K):
		for k2 in xrange(K):
			for index in part1[k1]:
				if index in part2[k2]:
					MAT[k1][k2] += 1
	cost_MAT = []
	for row in MAT:
		cost_row = []
		for col in row:
			cost_row += [sys.maxint - col]
		cost_MAT += [cost_row]

	m = Munkres()
	indexes = m.compute(cost_MAT)

	return indexes, MAT
'''























































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































"""13
def multi_search_func2(args, data):
	
	from sp_utilities import model_blank, model_circle
	from sp_alignment import ang_n
	
	stack = data[0]
	numr = data[1]
	mode = data[2]
	maxrin = data[3]
	
	nima = EMUtil.get_image_count(stack)	
	for im in xrange(nima):
		alpha = args[im]
		alpha = ang_n(alpha+1, mode, maxrin)
		img = EMData()
		img.read_image(stack, im)
		img.set_attr_dict({"alpha":alpha})
		img.write_image(stack, im)
	wie, var = aves_wiener(stack, "a")
	mask = model_circle(72, 150, 150)
	h = Util.infomask(var, mask, True)
	print h
	
	return -h[0]
"""































































































































































































































































































'''14
# This code looks obsolete, I do not write it. JB.. So I commented it out, PAP 12/31/09
def k_means_aves(images, N, K, rand_seed, outdir):
	from sp_utilities import model_blank
	from random       import seed, randint
	from sys import exit
	
	#  This version is not quite correct, as ctf2 is not modified in the average, but it cannot be done any other simple way :-(
	seed(rand_seed)
	assign = [0]*N
	nx = images[0].get_xsize()
	ny = images[0].get_ysize()
	nz = images[0].get_zsize()
	norm = nx*ny*nz
	e = model_blank(nx, ny, nz)

	Cls  = [0]*K #  number of elements in each class
	suma = []
	for k in xrange(K): suma.append(e.copy())
	#initialize randomly
	init_method = "Random"
	for i in xrange(3,6): assign[i]=1
	if(init_method == "Random"):
		retrial = 20
		while (retrial > 0):
			retrial -= 1
			#for im in xrange(N):  assign[im] = randint(0, K-1)
			for im in xrange(N):  Cls[assign[im]] +=1
			ier = 1
			k = K
			while( k > 0 and ier):
				k -= 1
				if(Cls[k] == 0):
					ier =0
					if(retrial == 0): ERROR(" Empty class in the initialization", "init_kmeans_aves", 1)
					for k in xrange(K): Cls[k] = 0
			if(ier == 1):  retrial = 0
	#  Calculate sums of images
	for im in xrange(N): Util.add_img(suma[assign[im]], images[im])
	# calculate criterion
	CRIT = [0.0]*K
	CT = 0.0
	for k in xrange(K):
		suma[k] = Util.mult_scalar(suma[k], 1.0/float(Cls[k]))
		CRIT[k] += norm*suma[k].cmp("dot",suma[k],{"negative":0})
		CT += CRIT[k]
		print  k,"  ",CRIT[k]
	print  " TOTAL = ",CT
	print  " Cls ",Cls
	# clustering
	from random import shuffle
	order = range(N)
	cnt = 0
	change = True
	maxit = 100
	while (change and cnt < maxit):
		#shuffle(order)
		cnt += 1
		change = False
		for imn in xrange(N):
			im = order[imn]
			#current assignment
			ca = assign[im]
			e = Util.subn_img( Util.mult_scalar(suma[ca], float(Cls[ca])), images[im] )
			JMINUS = norm*e.cmp("dot",e,{"negative":0})
			print  "JMINUS  ",im,ca, JMINUS
			JMINUS /= float(Cls[ca]-1)**2
			print  "JMINUS  ",im,ca, JMINUS
			Gain = [0.0]*K
			Gain_max = 0.0
			assign_to = -1
			for k in xrange(K):
				#  consider moving object assign[im] to remining K-1 groups
				if(k != ca):
					e = Util.subn_img( Util.mult_scalar(suma[k], float(Cls[k])), images[im] )
					JPLUS = norm*e.cmp("dot",e,{"negative":0})
					JPLUS /= float(Cls[k]+1)**2
					Gain[k] = JMINUS + JPLUS - CRIT[ca] - CRIT[k]
					print  "gain  ",k,"  ",Gain[k], JPLUS
					if(Gain[k] > Gain_max):
						Gain_max = Gain[k]
						assign_to = k
						JPLUSk = JPLUS
						print  "ASSIGNED to ",k,Gain_max
			# if improvement, move object
			if(assign_to > -1):
				print  "   #####################    MOVING OBJECT",im,Cls,CRIT
				CT += Gain[assign_to]
				assign[im] = assign_to
				Cls[ca] -= 1
				CRIT[ca] = JMINUS
				Cls[assign_to] += 1	
				CRIT[assign_to] = JPLUSk
				print  "   #####################    MOVING OBJECT",im,assign_to,CT, Cls,CRIT
				change = True
		print " ITERATION ",cnt
		print  CT
		print  CRIT
		print  assign
	exit()
'''








































































































































"""15
	from math import sqrt
	meanerror = residual = 0.0
	for x, y in map(None, X, Y):
		meanerror += (y - Sy/N)**2
		residual  += (y - a * x - b)**2
	RR = 1.0 - residual/meanerror
	ss = residual / (N-2)
	Var_a, Var_b = ss * N / det, ss * Sxx / det
	print "y=ax+b"
	print "N= %d" % N
	print "a= %g \\pm t_{%d;\\alpha/2} %g" % (a, N-2, sqrt(Var_a)) 
	print "b= %g \\pm t_{%d;\\alpha/2} %g" % (b, N-2, sqrt(Var_b))
	print "R^2= %g" % RR
	print "s^2= %g" % ss
	"""











































































































































































































































































































































































































"""16
	# write out information
	from sp_utilities import write_text_file
	write_text_file(cent, "cent")
	for k in xrange(K):
		cent = []
		for i in xrange(N):
			if(assign[i] == k):  cent.append(i)
		write_text_file(assign, "assign%03d"%(k))
	"""






























































































































































































































































































































































































































"""17
			if( scratch == None):
				self.file = os.path.join(sdir , "maskedimg%04d.bin" % self.myid )
			else:
				self.file = os.path.join(scratch , "maskedimg%04d.bin" % self.myid )
			"""


"""18
			if( scratch == None):
				self.file = os.path.join(sdir , "maskedimg.bin" )
			else:
				self.file = os.path.join(scratch , "maskedimg.bin" )
			"""
















"""19
	def writedat( self, data ):
		import array

		if self.fw is None:
			self.fw = open( self.file, "wb" )

		data.tofile( self.fw )

	def read_dat( self, data ):
		from numpy import fromfile, float32
		if not(self.fw is None) and not( self.fw.closed ):
			self.fw.close()

		assert not(self.fr is None) and not self.fr.closed
		Util.readarray( self.fr, data, self.ncov )
		if not(self.avgdat is None):
			data -= self.avgdat
	"""


































"""20
	def shuffle( self ):
		assert self.bufused
		from random import shuffle, seed
		from numpy  import zeros, float32, array
		from string import replace
		seed( 10000 + 10*self.myid )

		shfflfile = replace( self.file, "masked", "shuffled" )

		#print self.myid, "shuffling"
		sumdata = zeros( (self.ncov), float32 )
		imgdata = zeros( (self.ncov), float32 )
		self.fr = open( self.file, "rb" )
		self.avgdata = None

		fw = open( shfflfile, "wb" )
		for i in xrange(self.nimg):
			self.read_dat( imgdata )
			shuffle( imgdata )
			sumdata += imgdata
			imgdata.tofile( fw )

		self.fr.close()
		fw.close()

		if self.MPI:
			from mpi import mpi_reduce, mpi_bcast, MPI_FLOAT, MPI_INT, MPI_SUM, MPI_COMM_WORLD
			sumdata = mpi_reduce( sumdata, self.ncov, MPI_FLOAT, MPI_SUM, 0, MPI_COMM_WORLD )
			sumdata = mpi_bcast(  sumdata, self.ncov, MPI_FLOAT, 0, MPI_COMM_WORLD )
			sumdata = array(sumdata, float32)
 
			sumnimg = mpi_reduce( self.nimg, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD )
			sumnimg = mpi_bcast(  sumnimg,   1, MPI_INT, 0, MPI_COMM_WORLD )

		self.file = shfflfile
		self.avgdat = sumdata[:]/float(sumnimg)
		#print "done shuffling,nimg:", float(sumnimg)
	"""









"""21
	def insert( self, img ):
		assert self.mask.get_xsize()==img.get_xsize()
		assert self.mask.get_ysize()==img.get_ysize()
		assert self.mask.get_zsize()==img.get_zsize()

		from sp_utilities import get_image_data
		tmpimg = Util.compress_image_mask( img, self.mask )
		tmpdat = get_image_data(tmpimg)
		self.writedat( tmpdat )                                   #   WRITEDAT
		self.nimg +=1
		self.ncov = tmpimg.get_xsize()
	"""







































































































































































































































































































































































































































































































































































































