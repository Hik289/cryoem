








































































































































































































































































































































































































































'''0
def golden(func, args=(), brack=None, tol=1.e-4, full_output=0):
	""" Given a function of one-variable and a possible bracketing interval,
	return the minimum of the function isolated to a fractional precision of
	tol. A bracketing interval is a triple (a,b,c) where (a<b<c) and
	func(b) < func(a),func(c).  If bracket is two numbers then they are
	assumed to be a starting interval for a downhill bracket search
	(see bracketing)

	Uses analog of bisection method to decrease the bracketed interval.
	"""
	from sp_utilities import bracketing
	if brack is None:
		xa,xb,xc,fa,fb,fc,funcalls = bracketing(func, args=args)
	elif len(brack) == 2:
		xa,xb,xc,fa,fb,fc,funcalls = bracketing(func, xa=brack[0], xb=brack[1], args=args)
	elif len(brack) == 3:
		xa,xb,xc = brack
		if (xa > xc):  # swap so xa < xc can be assumed
			dum = xa; xa=xc; xc=dum
		assert ((xa < xb) and (xb < xc)), "Not a bracketing interval."
		fa = apply(func, (xa,)+args)
		fb = apply(func, (xb,)+args)
		fc = apply(func, (xc,)+args)
		assert ((fb<fa) and (fb < fc)), "Not a bracketing interval."
		funcalls = 3
	else:
		raise ValueError, "Bracketing interval must be length 2 or 3 sequence."

	_gR = 0.61803399
	_gC = 1.0-_gR
	x3 = xc
	x0 = xa
	if (abs(xc-xb) > abs(xb-xa)):
		x1 = xb
		x2 = xb + _gC*(xc-xb)
	else:
		x2 = xb
		x1 = xb - _gC*(xb-xa)
	f1 = apply(func, (x1,)+args)
	f2 = apply(func, (x2,)+args)
	funcalls += 2
	while (abs(x3-x0) > tol*(abs(x1)+abs(x2))):
		if (f2 < f1):
			x0 = x1; x1 = x2; x2 = _gR*x1 + _gC*x3
			f1 = f2; f2 = apply(func, (x2,)+args)
		else:
			x3 = x2; x2 = x1; x1 = _gR*x2 + _gC*x0
			f2 = f1; f1 = apply(func, (x1,)+args)
		funcalls += 1
	if (f1 < f2):
		xmin = x1
		fval = f1
	else:
		xmin = x2
		fval = f2
	if full_output:
		return xmin, fval, funcalls
	else:
		return xmin


def bracketing(func, xa=0.0, xb=1.0, args=(), grow_limit=110.0, maxiter=1000):
	"""Given a function and distinct initial points, search in the downhill
	direction (as defined by the initital points) and return new points
	xa, xb, xc that bracket the minimum of the function:
	f(xa) > f(xb) < f(xc)
	"""
	_gold = 1.618034
	_verysmall_num = 1e-21
	fa = apply(func, (xa,)+args)
	fb = apply(func, (xb,)+args)
	if (fa < fb):			   # Switch so fa > fb
		dum = xa; xa = xb; xb = dum
		dum = fa; fa = fb; fb = dum
	xc = xb + _gold*(xb-xa)
	fc = apply(func, (xc,)+args)
	funcalls = 3
	iter = 0
	while (fc < fb):
		tmp1 = (xb - xa)*(fb-fc)
		tmp2 = (xb - xc)*(fb-fa)
		val = tmp2-tmp1
		if abs(val) < _verysmall_num:
		denom = 2.0*_verysmall_num
		else:
		denom = 2.0*val
		w = xb - ((xb-xc)*tmp2-(xb-xa)*tmp1)/denom
		wlim = xb + grow_limit*(xc-xb)
		if iter > maxiter:
		raise RuntimeError, "Too many iterations."
		iter += 1
		if (w-xc)*(xb-w) > 0.0:
		fw = apply(func, (w,)+args)
		funcalls += 1
		if (fw < fc):
			xa = xb; xb=w; fa=fb; fb=fw
			return xa, xb, xc, fa, fb, fc, funcalls
		elif (fw > fb):
			xc = w; fc=fw
			return xa, xb, xc, fa, fb, fc, funcalls
		w = xc + _gold*(xc-xb)
		fw = apply(func, (w,)+args)
		funcalls += 1
		elif (w-wlim)*(wlim-xc) >= 0.0:
		w = wlim
		fw = apply(func, (w,)+args)
		funcalls += 1
		elif (w-wlim)*(xc-w) > 0.0:
		fw = apply(func, (w,)+args)
		funcalls += 1
		if (fw < fc):
			xb=xc; xc=w; w=xc+_gold*(xc-xb)
			fb=fc; fc=fw; fw=apply(func, (w,)+args)
			funcalls += 1
		else:
		w = xc + _gold*(xc-xb)
		fw = apply(func, (w,)+args)
		funcalls += 1
		xa=xb; xb=xc; xc=w
		fa=fb; fb=fc; fc=fw
	return xa, xb, xc, fa, fb, fc, funcalls
'''










































"""1
		Put an input image into image center (nx/2, ny/2) using method :
		1. phase_cog
		2. cross-correlate with Gaussian function
		3. cross-correlate with donut shape image
		4. cross-correlate with reference image provided by user
		5. cross-correlate with self-rotated average
		7. binarize at ave+sigma and cross-correlate with a circle
			The function will return centered_image, and shifts
	"""























































































































































































































"""Print the composition of two transformations  T2*T12
		Here  if v's are vectors:   vnew = T2*T1 vold
			 with T1 described by alpha1, sx1, scale1 etc.

	  Combined parameters correspond to image first transformed by set 1 followed by set 2.

		Usage: compose_transform2(alpha1,sx1,sy1,mirror1,scale1,alpha2,sx2,sy2,mirror2,scale2)
		   angles in degrees
	"""
































































































"""3
	t1.printme()
	sxprint(" ")
	t2.printme()
	sxprint(" ")
	tt.printme()
	"""






























































































































































































"""Create a list of Euler angles suitable for projections.4
	   method is either 'S' - for Saff algorithm
				   or   'P' - for Penczek '94 algorithm
					 'S' assumes phi1<phi2 and phi2-phi1>> delta ;
	   symmetry  - if this is set to point-group symmetry (cn or dn) or helical symmetry with point-group symmetry (scn or sdn), \
					 it will yield angles from the asymmetric unit, not the specified range;
	   ant - neighborhood for local searches.  I believe the fastest way to deal with it in case of point-group symmetry
				it to generate cushion projections within an/2 of the border of unique zone
	"""
















































































































"""5
	elif(symmetry_string[0]  == "o"):
		from EMAN2 import parsesym
		if(method.lower() == "s"):  met = "saff"
		elif(method.lower() == "p"): met = "even"
		if(theta2 == 180.0):  inc_mirror = 1
		else:  inc_mirror = 0
		tt = parsesym(symmetry)
		z = tt.gen_orientations(met,{"delta":delta,"inc_mirror":inc_mirror})
		angles = []
		if( phiEqpsi == "Minus" ):
			for q in z:
				q = q.get_params("spider")
				angles.append([q["phi"], q["theta"],-q["phi"]])
		else:
			for q in z:
				q = q.get_params("spider")
				angles.append([q["phi"], q["theta"],0.0])
	else :
		
		# This is very close to the Saff even_angles routine on the asymmetric unit;
		# the only parameters used are symmetry and delta
		# The formulae are given in the Transform Class Paper
		# The symmetric unit 		nVec=[]; # x,y,z triples
		# is defined by three points b,c, v of Fig 2 of the paper
		# b is (0,0,1)
		# c is (sin(thetac),0,cos(thetac))
		# a is (sin(thetac)cos(Omega),sin(thetac)cos(Omega),cos(thetac))
		# f is the normalized sum of all 3

		# The possible symmetries are in list_syms
		# The symmetry determines thetac and Omega
		# The spherical area is Omega - pi/3;
		#  should be equal to 4 *pi/(3*# Faces)
		#
		# symmetry ='tet';   delta  = 6;

		scrunch = 0.9  # closeness factor to eliminate oversampling corners
		#nVec=[]       # x,y,z triples

		piOver = pi/180.0
		Count=0   # used to count the number of angles

		if (symmetryLower[0:3] =="tet"):  m=3.0; fudge=0.9 # fudge is a factor used to adjust phi steps
		elif (symmetryLower[0:3] =="oct"):  m=4.0; fudge=0.8
		elif (symmetryLower[0:3] =="ico"):  m=5.0; fudge=0.95
		else: ERROR("allowable symmetries are cn, dn, tet, oct, icos","even_angles",1)

		n=3.0
		OmegaR = 2.0*pi/m; cosOmega= cos(OmegaR)
		Edges  = 2.0*m*n/(2.0*(m+n)-m*n)
		Faces  = 2*Edges/n
		Area   = 4*pi/Faces/3.0; # also equals  2*pi/3 + Omega
		costhetac = cosOmega/(1-cosOmega)
		deltaRad= delta*pi/180
		NumPoints = int(Area/(deltaRad*deltaRad))
		fheight = 1/sqrt(3)/ (tan(OmegaR/2.0))

		z0      = costhetac  # initialize loop
		z       = z0
		phi     = 0
		Deltaz  = (1-costhetac)/(NumPoints-1)

		#[1, phi,180.0*acos(z)/pi,0.]
		anglesLast = [phi,180.0*acos(z)/pi,0.]
		angles.append(anglesLast)
		nLast=  [ sin(acos(z))*cos(phi*piOver) ,  sin(acos(z))*sin(phi*piOver) , z]
		nVec = []
		nVec.append(nLast)

		Count +=1

		for k in xrange(1,(NumPoints-1)):
			z=z0 + Deltaz*k  # Is it higher than fhat or lower
			r= sqrt(1-z*z)
			if (z > fheight): phiRmax= OmegaR/2.0
			if (z<= fheight):
				thetaR   = acos(z);
				cosStuff = (cos(thetaR)/sin(thetaR))*sqrt(1. - 2 *cosOmega);
				phiMax   =  180.0*( OmegaR - acos(cosStuff))/pi
			angleJump = fudge* delta/r
			phi = (phi + angleJump)%(phiMax)
			anglesNew = [phi,180.0*acos(z)/pi,0.];
			nNew = [ sin(acos(z))*cos(phi*piOver) ,  sin(acos(z))*sin(phi*piOver) , z]
			diffangleVec = [acos(nNew[0]*nVec[k][0] +   nNew[1]*nVec[k][1] +    nNew[2]*nVec[k][2] ) for k in xrange(Count)]
			diffMin = min(diffangleVec)
			if (diffMin>angleJump*piOver *scrunch):
				Count +=1
				angles.append(anglesNew)
				nVec.append(nNew)
				#[Count, phi,180*acos(z)/pi,0.]
			anglesLast = anglesNew
			nLast=nNew

		angles.append( [0.0, 0.0, 0.0] )
		nLast=  [ 0., 0. , 1.]
		nVec.append(nLast)
		if(theta2 == 180.0):   angles.append( [0.0, 180.0, 0.0] )

		angles.reverse()
		if(phiEqpsi == "Minus"):
			for i in xrange(len(angles)):  angles[i][2] = (720.0-angles[i][0])%360.0
		#print(Count,NumPoints)

		#		look at the distribution
		#		Count =len(angles); piOver= pi/180.0;
		#		phiVec    =  [ angles[k][0] for k in range(Count)] ;
		#		thetaVec  =  [ angles[k][1] for k in range(Count)] ;
		#		xVec = [sin(piOver * angles[k][1]) * cos(piOver * angles[k][0]) for k in range(Count) ]
		#		yVec = [sin(piOver * angles[k][1])* sin(piOver * angles[k][0]) for k in range(Count) ]
		#		zVec = [cos(piOver *  angles[k][1]) for k in range(Count) ]
		#		pylab.plot(yVec,zVec,'.'); pylab.show()
		"""




























































































































































































































































































































































"""6
	Create an image of a Gaussian function with standard deviation "xsigma,ysigma,zsigma"
	 and centered at (xcenter,ycenter,zcenter), by default the center is image center.
	"""

















































































































































































































































































































































































































































































































































"""7
		Print formated elements in a list to screen
		The screen output is in the form of narray*int(len(m)/narray)
		Or when narray is zero, int(sqrt(len(m)))*int(sqrt(len(m)))
	"""
































































































































































































































































































































































"""8
		Substitute masked area value with image average
	"""

























































































































"""9
		linearly interpolate a 1D power spectrum to required length with required Pixel size
		input_object - a 1D list with a 1D curve to be interpolated
		length_current - half size of the image size (in case of power spectrum, it can be different from the length of the input_object)
		length_interpolated - length of the interpolated 1D curve
		Pixel_size_current - pixel size of the input 1D list
		Pixel_size_interpolated - pixel size of the target 1D list
		One can either input the two lengths or two respective pixel sizes
	"""







































































































































































































































































































"""10
def reduce_array_to_root(data, myid, main_node = 0, comm = -1):
	from numpy import array, shape, reshape
	from mpi import MPI_FLOAT, MPI_SUM, MPI_COMM_WORLD, mpi_reduce, mpi_barrier

	if comm == -1:  comm = MPI_COMM_WORLD
	n = shape(data)
	ntot = 1
	for i in xrange(len(n)):  ntot *= n[i]
		count = 500000
		array1d = reshape(data, (ntot,))
		ntime = (ntot-1) /count + 1
		for i in xrange(ntime):
			block_begin = i*count
			block_end   = i*count + count
			if block_end > ntot: block_end = ntot
			block_size  = block_end - block_begin
			tmpsum = mpi_reduce(array1d[block_begin], block_size, MPI_FLOAT, MPI_SUM, main_node, comm)
		mpi_barrier(comm)
			if myid == main_node:
				array1d[block_begin:block_end] = tmpsum[0:block_size]
"""













































































































































































































































































"""11

	The assumption in <<gather_compacted_EMData_to_root>> is that each processor
	calculates part of the list of elements and then each processor sends
	its results to the root

	Therefore, each processor has access to the header. If we assume that the
	attributes of interest from the header are the same for all elements then
	we can copy the header and no mpi message is necessary for the
	header.

	"""


















































































































































































































































































"""12
def bcast_EMData_to_all(img, myid, main_node = 0, comm = -1):

	# Comment by Zhengfan Yang on 01/05/10
	#
	# Notice:
	# (1) one should use this new version of broadcasting EMData in the following way:
	# 	img = bcast_EMData_to_all(img, myid, main_node, comm)
	# instead of
	# 	bcast_EMData_to_all(img, myid, main_node, comm)
	# The latter is inconsistent with mpi_bcast() and difficult to implement efficiently
	#
	# (2) To be consistent with send_EMData() and recv_EMData(), we assume that the node
	# other than the broadcasting node know nothing about the EMData(). Therefore, one
	# need to broadcast the size of EMData() and two attributes: is_complex and is_ri.
	# For all other attributes, you are on your own.

	from numpy import reshape
	from mpi import mpi_bcast, MPI_INT, MPI_FLOAT, MPI_COMM_WORLD

	if comm == -1: comm = MPI_COMM_WORLD

	img_head = []
	if myid == main_node:
		img_head.append(img.get_xsize())
		img_head.append(img.get_ysize())
		img_head.append(img.get_zsize())
		img_head.append(img.is_complex())
		img_head.append(img.is_ri())
	img_head = mpi_bcast(img_head, 5, MPI_INT, main_node, comm)
	nx = int(img_head[0])
	ny = int(img_head[1])
	nz = int(img_head[2])
	is_complex = int(img_head[3])
	is_ri = int(img_head[4])

	ntot = nx*ny*nz
	img_data = EMNumPy.em2numpy(img)
	img_data = mpi_bcast(img_data, ntot, MPI_FLOAT, main_node, comm)
	if nz != 1:
		img_data = reshape(img_data, (nz, ny, nx))     # For some reason, the order should be like this -- Zhengfan Yang
	elif ny != 1:
		img_data = reshape(img_data, (ny, nx))
	else:
		pass
	img = numpy2em_python(img_data)
	img.set_complex(is_complex)
	img.set_ri(is_ri)

	return img


def reduce_EMData_to_root(img, myid, main_node = 0, comm = -1):

	# Comment by Zhengfan Yang on 01/05/10
	#
	# Notice:
	# (1) one should use this new version of reducing EMData in the following way:
	# 	img = reduce_EMData_to_root(img, myid, main_node, comm)
	# instead of
	# 	reduce_EMData_to_root(img, myid, main_node, comm)
	# The latter is inconsistent with mpi_bcast() and difficult to implement efficiently

	from numpy import reshape
	from mpi   import mpi_reduce, MPI_FLOAT, MPI_SUM, MPI_COMM_WORLD

	if comm == -1: comm = MPI_COMM_WORLD

	nx = img.get_xsize()
	ny = img.get_ysize()
	nz = img.get_zsize()
	is_complex = img.is_complex()
	is_ri = img.is_ri()
	ntot = nx*ny*nz

	img_data = EMNumPy.em2numpy(img)
	img_data = mpi_reduce(img_data, ntot, MPI_FLOAT, MPI_SUM, main_node, comm)

	if myid == main_node:
		if nz!=1:
			img_data = reshape(img_data, (nz, ny, nx))
		elif ny!=1:
			img_data = reshape(img_data, (ny, nx))
		else:
			pass

		img = numpy2em_python(img_data)
		img.set_complex(is_complex)
		img.set_ri(is_ri)
		return img
	else:
		return img
"""




























"""13
	count = 100000
	data1d = reshape(img_data, (ntot,))
	ntime = (ntot-1) /count + 1

	for i in xrange(ntime):
		block_begin = i*count
		block_end   = i*count + count
		if block_end > ntot:
			block_end = ntot
		block_size  = block_end - block_begin
		mpi_send(data1d[block_begin], block_size, MPI_FLOAT, dst, data_tag*ntime+i, comm)
	"""












































"""14
	#construct a EMData by taking the ownership of numpy array, no memory copying  --Grant Tang
	#recv_data_numeric = mpi_recv(ntot, MPI_FLOAT, src, data_tag, comm)
	#recv_data_numpy = numpy.array(recv_data_numeric)
	#numpy_data = recv_data.reshape(recv_data, (nz,ny,nx))
	#img = numpy2em_python(numpy_data)

	#comment out Wei's original code, which makes memory copy to construct EMData from numpy array  --Grant Tang
	img = EMData()
	img.set_size(nx, ny, nz)
	if( complex > 0 ):
		img.set_complex(True)
	else:
		img.set_complex(False)

	data1d = reshape( get_image_data(img), (ntot,) )
	tmp_data = mpi_recv(ntot, MPI_FLOAT, src, data_tag, comm)
		data1d[0:ntot] = tmp_data[0:ntot]


	count = 100000
	ntime = (ntot-1)/count + 1

	for i in xrange(ntime):
		block_begin = i*count
		block_end   = i*count + count
		if block_end > ntot:
			block_end = ntot
		block_size  = block_end - block_begin
		tmp_data = mpi_recv(block_size, MPI_FLOAT, src, data_tag*ntime+i, comm)
		data1d[block_begin:block_end] = tmp_data[0:block_size]

	return img
	"""

























































































































































































































































































































































































































































"""15
#  This would not work on windows
def memory_usage():
	import os
	from string import split
	return 0
	file = "/proc/%d/status" % os.getpid()
	f = open(file, 'r')
	line = f.readline()
	while len(line) > 0 :
		items = split( line )
		if items[0]=='VmSize:':
			return items[1]+items[2]
		line = f.readline()
"""
























































































































































































































































































































































"""16
getang3 = angle_between_projections_directions
def getang3(p1,p2):
	from sp_utilities import getfvec, lacos
	n1 = getfvec(p1[0],p1[1])
	n2 = getfvec(p2[0],p2[1])
	return lacos(n1[0]*n2[0]+n1[1]*n2[1]+n1[2]*n2[2])
"""



































































"""17
Util.nearest_ang(vecs, vec[0],vec[1],vec[2])
def closest_ang( vecs, vec) :
	best_s = -1.0
	best_i = -1

	for i in xrange( len(vecs) ):
		s = abs(vecs[i][0]*vec[0] + vecs[i][1]*vec[1] + vecs[i][2]*vec[2])
		if s > best_s:
			best_s = s
			best_i = i

	return best_i
"""











































































































































































































"""18
def assign_projangles(projangles, refangles, return_asg = False):

	if len(refangles) > 10000:
		if len(refangles) > 100000:
			coarse_refangles = even_angles(1.5)   # 9453 angles
		else:
			coarse_refangles = even_angles(5.0)   # 849 angles
		coarse_asg = assign_projangles(projangles, coarse_refangles, True)
		ref_asg = assign_projangles(refangles, coarse_refangles, True)
	else:
		coarse_refangles = []
		coarse_asg = []
		ref_asg = []

	nproj = len(projangles)
	nref = len(refangles)
	proj_ang = [0.0]*(nproj*2)
	ref_ang = [0.0]*(nref*2)
	for i in xrange(nproj):
		proj_ang[i*2] = projangles[i][0]
		proj_ang[i*2+1] = projangles[i][1]
	for i in xrange(nref):
		ref_ang[i*2] = refangles[i][0]
		ref_ang[i*2+1] = refangles[i][1]

	asg = Util.assign_projangles(proj_ang, ref_ang, coarse_asg, ref_asg, len(coarse_refangles))
	if return_asg: return asg
	assignments = [[] for i in xrange(nref)]
	for i in xrange(nproj):
		assignments[asg[i]].append(i)

	return assignments
"""











































































































































































































"""19
Pushed to C
Util.cone_dirs_f(projdirs, ancordir, ant)
Returns a list of projdirs indexes that are within ant degrees of ancordir
ant in degrees
def cone_dirs_f( projdirs, ancordir, ant):
	from math import cos, pi, degrees, radians
	#  ancordir contains a list of symmetry neighbors
	#  Returns a list of projdirs indexes that are within ant degrees of ancordir
	cone = cos(radians(ant))
	la = []
	for i,vecs in enumerate(projdirs):
		s = -2.0
		for d in ancordir:
			s = max(vecs[0]*d[0] + vecs[1]*d[1] + vecs[2]*d[2], s)
		if s >= cone :
			la.append(i)
	return la
"""

"""20
def cone_ang_f_with_index( projangles, phi, tht, ant ):
	from sp_utilities import getvec
	from math import cos, pi, degrees, radians
	# vec = getvec( phi, tht )
	vec = getfvec( phi, tht )

	cone = cos(radians(ant))
	la = []
	index = []
	for i in xrange( len(projangles) ):
		vecs = getfvec( projangles[i][0], projangles[i][1] )
		s = vecs[0]*vec[0] + vecs[1]*vec[1] + vecs[2]*vec[2]
		if s >= cone:
		# if abs(s) >= cone:
			la.append(projangles[i])
			index.append(i)
	return la, index
"""
























"""21
def cone_vectors( normvectors, phi, tht, ant ):
	from sp_utilities import getvec
	from math import cos, pi, degrees, radians
	vec = getvec( phi, tht )

	cone = cos(radians(ant))
	la = []
	for i in xrange( len(normvectors) ):
		s = abs(normvectors[i][0]*vec[0] + normvectors[i][1]*vec[1] + normvectors[i][2]*vec[2])
		if s >= cone:
			la.append(normvectors[i])

	return la
"""









































































































































































































































































































































"""22
Not used and possibly incorrect
def phi_theta_to_xyz(ang):
	from math import sin, cos, pi, radians
	phi   = radians( ang[0] )
	theta = radians( ang[1] )
	z = cos(theta)
	x = sin(theta) * cos(phi)
	y = sin(theta) * sin(phi)
	return [x, y, z]


def xyz_to_phi_theta(xyz):
	from math import pi, acos, sqrt, degrees, atan2
	theta = acos(xyz[2])
	phi   = atan2(xyz[1], xyz[0])
	return [ degrees(phi), degrees(theta), 0.0]

# input: list of triplets (phi, theta, psi)
# output: average triplet: (phi, theta, psi)
def average_angles(angles):
	from math import sqrt
	# convert to x, y, z
	ex = 0.0
	ey = 0.0
	ez = 0.0
	sum_psi = 0.0
	for ang in angles:
		xyz = phi_theta_to_xyz(ang)
		ex += xyz[0]
		ey += xyz[1]
		ez += xyz[2]
		sum_psi += ang[2]
	ex /= len(ang)
	ey /= len(ang)
	ez /= len(ang)
	divider = sqrt(ex*ex + ey*ey + ez*ez)
	xyz = [ ex/divider, ey/divider, ez/divider ]
	r = xyz_to_phi_theta(xyz)
	r[2] = sum_psi / len(angles)  # TODO - correct psi calculations !!!!
	return r
"""




















































































































































































































































































































































































































































































































































































"""23
		for j in xrange(N):
			d = ang_diff(vec[j], vec[k])
			g[j][0] = d[0]
			g[j][1] = d[1]
			g[j][2] = j
		g.sort()
		for j in xrange(img_per_grp):
			neighbor2[j] = g[j][2]
			dis2[j] = g[j][0]
		t3 = time()
		print "Members in common = %3d   extra delta = %6.3f   time1 = %5.2f   time2 = %5.2f"%(len(Set(neighbor).intersection(Set(neighbor2))),
		dis[-1]-dis2[-1], t2-t1, t3-t2)
		"""






















"""24
def findall(val, lo):
	'''
	  Find all occurrences of val in list lo
	  Returns a list of indices of val in lo.
	'''
	u = []
	i = -1
	while( i < len(lo)-1):
		try:
			i = lo.index(val,i+1)
			u.append(i)
		except:
			i += 1
	return  u
"""



























































"""25
Iterators over sequence of images. They work for lists and stacks of images.
Additional time cost: about 1 second per 10^6 iterations on 3 GHz processor.

Usage:

it = iterImagesList(list_of_images)  <-or->  it = iterImagesStack(stack_with_images)
while it.goToNext():
	do_something(it.image())

"""






























































































































































































































































































"""26
	It is assumed that this code or equivalent is ran before calling this function

	mpi_init(0, [])

	mpi_comm = MPI_COMM_WORLD
	main_node = 0

	my_rank = mpi_comm_rank(mpi_comm)
	mpi_size = mpi_comm_size(mpi_comm)

	shared_comm = mpi_comm_split_type(mpi_comm, MPI_COMM_TYPE_SHARED,  0, MPI_INFO_NULL)

	sh_my_rank = mpi_comm_rank(shared_comm)
	key = sh_my_rank
	sh_mpi_size = mpi_comm_size(shared_comm)

	masters_from_groups_vs_everything_else_comm = mpi_comm_split(mpi_comm, sh_my_rank == main_node, my_rank)
	"""





































































































































































































































































































































"""27
	if( myid == main_node ):
		print "  "
		line = strftime("%Y-%m-%d_%H:%M:%S", localtime()) + " =>"
		print  line, "Reading data  onx: %3d, nx: %3d, CTF: %s, applyctf: %s, preshift: %s."%(Tracker["constants"]["nnxo"], nxinit, Tracker["constants"]["CTF"], Tracker["applyctf"], preshift)
		print  "                       stack:      %s\n                       partids:     %s\n                       partstack: %s\n"%(Tracker["constants"]["stack"], partids, partstack)
	"""




































































































'''28
def get_shrink_data(Tracker, nxinit, partids, partstack, bckgdata = None, myid = 0, main_node = 0, nproc = 1, \
					original_data = None, return_real = False, preshift = False, apply_mask = True, large_memory = True):
	"""
	This function will read from stack a subset of images specified in partids
	   and assign to them parameters from partstack with optional CTF application and shifting of the data.
	So, the lengths of partids and partstack are the same.
	  The read data is properly distributed among MPI threads.

	Flow of data:
	1. Read images, if there is enough memory, keep them as original_data.
	2. Read current params
	3.  Apply shift
	4.  Normalize outside of the radius
	5.  Do noise substitution and cosine mask.  (Optional?)
	6.  Shrink data.
	7.  Apply CTF.

	"""
	#from fundamentals import resample
	from sp_utilities    import get_im, model_gauss_noise, set_params_proj, get_params_proj
	from sp_fundamentals import fdecimate, fshift, fft
	from sp_filter       import filt_ctf, filt_table
	from sp_applications import MPI_start_end
	from math         import sqrt


	if( myid == main_node ):
		print "  "
		line = strftime("%Y-%m-%d_%H:%M:%S", localtime()) + " =>"
		if(original_data == None or not large_memory):
			print  line, "Reading data  onx: %3d, nx: %3d, CTF: %s, applymask: %s, applyctf: %s, preshift: %s."%(Tracker["constants"]["nnxo"], nxinit, Tracker["constants"]["CTF"], apply_mask, Tracker["applyctf"], preshift)
		else:
			print  line, "Processing data  onx: %3d, nx: %3d, CTF: %s, applymask: %s, applyctf: %s, preshift: %s."%(Tracker["constants"]["nnxo"], nxinit, Tracker["constants"]["CTF"], apply_mask, Tracker["applyctf"], preshift)
		print  "                       stack:      %s\n                       partids:     %s\n                       partstack: %s\n"%(Tracker["constants"]["stack"], partids, partstack)
	if( myid == main_node ): lpartids = read_text_file(partids)
	else:  lpartids = 0
	lpartids = wrap_mpi_bcast(lpartids, main_node)
	ndata = len(lpartids)
	if( myid == main_node ):  partstack = read_text_row(partstack)
	else:  partstack = 0
	partstack = wrap_mpi_bcast(partstack, main_node)
	if( ndata < nproc):
		if(myid<ndata):
			image_start = myid
			image_end   = myid+1
		else:
			image_start = 0
			image_end   = 1
	else:
		image_start, image_end = MPI_start_end(ndata, nproc, myid)
	lpartids  = lpartids[image_start:image_end]
	partstack = partstack[image_start:image_end]
	#  Preprocess the data
	mask2D  = model_circle(Tracker["constants"]["radius"],Tracker["constants"]["nnxo"],Tracker["constants"]["nnxo"])
	nima = image_end - image_start
	oldshifts = [[0.0,0.0]]*nima
	data = [None]*nima
	if(original_data == None or not large_memory): original_data = [None]*nima
	shrinkage = nxinit/float(Tracker["constants"]["nnxo"])


	#  Note these are in Fortran notation for polar searches
	#txm = float(nxinit-(nxinit//2+1) - radius -1)
	#txl = float(2 + radius - nxinit//2+1)
	radius = int(Tracker["constants"]["radius"]*shrinkage + 0.5)
	txm = float(nxinit-(nxinit//2+1) - radius)
	txl = float(radius - nxinit//2+1)

	if bckgdata :
		nnx = bckgdata[0].get_xsize()
		nny = bckgdata[0].get_ysize()
		bckgnoise = []
		oneover = []
		for i in xrange(nny):
			prj = [0.0]*nnx
			prj[0] = 1.0
			for k in xrange(1,nnx): prj[k] = bckgdata[0].get_value_at(k,i)
			oneover.append(prj)
			for k in xrange(1,nnx):
				if( prj[k] > 0.0 ):  prj[k] = 1.0/sqrt(prj[k])
			bckgnoise.append(prj)

		datastamp = bckgdata[1]

	for im in xrange(nima):
		if(original_data[im] == None or not large_memory):
			original_data[im] = get_im(Tracker["constants"]["stack"], lpartids[im])

		phi,theta,psi,sx,sy = partstack[im][0], partstack[im][1], partstack[im][2], partstack[im][3], partstack[im][4]
		if preshift:
			data[im] = fshift(original_data[im], sx, sy)
			oldshifts[im] = [sx,sy]
			sx = 0.0
			sy = 0.0
		else:  data[im] = original_data[im].copy()
		st = Util.infomask(data[im], mask2D, False)
		data[im] -= st[0]
		data[im] /= st[1]
		if data[im].get_attr_default("bckgnoise", None) :  data[im].delete_attr("bckgnoise")
		#  Do bckgnoise if exists
		if bckgdata:
			try:
				stmp = data[im].get_attr("ptcl_source_image")
			except:
				try:
					stmp = data[im].get_attr("ctf")
					stmp = round(stmp.defocus,4)
				except:
					ERROR("Either ptcl_source_image or ctf has to be present in the header.","get_shrink_data",1, myid)
			try:
				indx = datastamp.index(stmp)
			except:
				ERROR("Problem with indexing ptcl_source_image.","get_shrink_data",1, myid)

			data[im].set_attr("bckgnoise",oneover[indx])
			if apply_mask:
				bckg = model_gauss_noise(1.0,Tracker["constants"]["nnxo"]+2,Tracker["constants"]["nnxo"])
				bckg.set_attr("is_complex",1)
				bckg.set_attr("is_fftpad",1)
				bckg = fft(filt_table(bckg,bckgnoise[indx]))
				#  Normalize bckg noise in real space, only region actually used.
				st = Util.infomask(bckg, mask2D, False)
				bckg -= st[0]
				bckg /= st[1]
				from sp_morphology import cosinemask
				data[im] = cosinemask(data[im],radius = Tracker["constants"]["radius"], bckg = bckg)
		else:
			#  if no bckgnoise, do simple masking instead
			if apply_mask:  data[im] = cosinemask(data[im],radius = Tracker["constants"]["radius"] )

		if( Tracker["constants"]["CTF"] and Tracker["applyctf"] ):
			data[im] = filt_ctf(data[im], data[im].get_attr("ctf"))
			data[im].set_attr('ctf_applied', 1)
		else:  apix = Tracker["constants"]["pixel_size"]

		#  resample will properly adjusts shifts and pixel size in ctf
		#data[im] = resample(data[im], shrinkage)
		#  return Fourier image
		data[im] = fdecimate(data[im], nxinit, nxinit, 1, return_real)
		try:
			ctf_params = original_data[im].get_attr("ctf")
			ctf_params.apix = ctf_params.apix/shrinkage
			data[im].set_attr('ctf', ctf_params)
		except:  pass
		if( Tracker["constants"]["CTF"] and Tracker["applyctf"] ):
			pass
		else:  data[im].set_attr('apix', apix/shrinkage)
		#  We have to make sure the shifts are within correct range, shrinkage or not
		set_params_proj(data[im],[phi,theta,psi,max(min(sx*shrinkage,txm),txl),max(min(sy*shrinkage,txm),txl)])
		#  For local SHC set anchor
		#if(nsoft == 1 and an[0] > -1):
		#  We will always set it to simplify the code
		###set_params_proj(data[im],[phi,theta,psi,0.0,0.0], "xform.anchor")
	assert( nxinit == data[0].get_ysize() )  #  Just to make sure.
	#oldshifts = wrap_mpi_gatherv(oldshifts, main_node, MPI_COMM_WORLD)
	return data, oldshifts, original_data
'''































































































































"""29

	When used it needs: from inspect import currentframe, getframeinfo
	Also: from sp_utilities import program_state_stack

	This function is used for restarting time consuming data processing programs/steps from the last saved point.

	This static variable must be defined before the first call:
	program_state_stack.PROGRAM_STATE_VARIABLES = {"isac_generation", "i", "j"}
	It contains local variables at any level of the stack that define uniquely the state(flow/logic) of the program.

	It is assumed that the processed data is saved at each step and it is independent from the variables that uniquely define
	the state(flow/logic) of the program. All the variables that are used in more than one step must be calculated before
	the "if program_state_stack(locals(), getframeinfo(currentframe())):" call. It is assumed that they are not time consuming.
	Passing processed data from one step to the next is done only through files.

	First call needs to contain "file_name_of_saved_state".
	Then, the next calls are "if program_state_stack(locals(), getframeinfo(currentframe())):" to demarcate the blocks of
	processing steps that take a long time (hours/days).

	Example of initialization:
	program_state_stack.PROGRAM_STATE_VARIABLES = {"isac_generation", "i", "j"}
	program_state_stack(locals(), getframeinfo(currentframe()), "my_state.json")

	Then regular usage in the program:

	if program_state_stack(locals(), getframeinfo(currentframe())):
	# if 1:
		pass

	"""



























































































































































































"""30
def debug_mpi_barrier(comm):
	from mpi import mpi_barrier, mpi_comm_rank, mpi_bcast
	from traceback import extract_stack
	import sys


	# if mpi_comm_rank(comm) in range(4):
	print "Stack info::0::", extract_stack()[-3:]

	sys.stdout.flush()
	sys.stderr.flush()
	return mpi_barrier(comm)


def debug_mpi_bcast(newv, s, t, m, comm):
	from mpi import mpi_comm_rank, mpi_bcast
	from traceback import extract_stack
	import sys


	rrr = mpi_bcast(newv, s, t, m, comm)
	# if mpi_comm_rank(comm) in range(4):
	print "Stack info::0::", extract_stack()[-3:], "****************", newv, "####", rrr

	sys.stdout.flush()
	sys.stderr.flush()

	# return mpi_bcast(newv, s, t, m, comm)
	return rrr
"""




















































































































































"""31
def remove_small_groups(class_list, minimum_number_of_objects_in_a_group):
	new_class = []
	final_list = []
	for one_class in class_list:
		if len(one_class) >= minimum_number_of_objects_in_a_group:
			new_class.append(one_class)
			for element in one_class:
				final_list.append(element)
	final_list.sort()
	return final_list, new_class
"""



























"""32
def remove_small_groups(class_list, minimum_number_of_objects_in_a_group):
	new_class = []
	final_list = []
	for one_class in class_list:
		if len(one_class) >= minimum_number_of_objects_in_a_group:
			new_class.append(one_class)
			for element in one_class:
				final_list.append(element)
	final_list.sort()
	return final_list, new_class
"""















"""33
def print_a_line_with_timestamp(string_to_be_printed):
	line = strftime("%Y-%m-%d_%H:%M:%S", localtime()) + " =>"
	sxprint((line, string_to_be_printed))
	return string_to_be_printed
"""











































































""" this commented previously34
		lowpass = 0.5
		ns = len(nfsc[1])
		#  This is resolution used to filter half-volumes
		for i in xrange(1,ns-1):
				if ( nfsc[1][i] < 0.5 ):
						lowpass = nfsc[0][i-1]
						break
		"""


































































































































































































































































































































































































































"""35
def get_number_of_groups(total_particles, number_of_images_per_group, round_off=0.2):
	number_of_groups = float(total_particles) / number_of_images_per_group
	if number_of_groups - int(number_of_groups) < round_off:
		number_of_groups = int(number_of_groups)
	else:
		number_of_groups = int(number_of_groups) + 1
	return number_of_groups
"""















































































"""36
def get_number_of_groups(total_particles, number_of_images_per_group):
	# soft partition groups
	number_of_groups = float(total_particles) / number_of_images_per_group
	if number_of_groups - int(number_of_groups) < 0.4:
		number_of_groups = int(number_of_groups)
	else:
		number_of_groups = int(number_of_groups) + 1
	return number_of_groups
"""










































































































































































































































































































































































































































































































































































































































































































































































"""37
	lina = numpy.argsort(radius_array)
	sorted_radius = radius_array[lina[::-1]]
	array_x = numpy.arange(sorted_radius.shape[0])
	angles_no_mirror = angles_no_mirror[lina[::-1]]
	nonzero_mask = list(nonzero_mask[0][lina[::-1]])

	"""


















"""38
	sxprint(array_x)
	sxprint(sorted_radius)
	sxprint(len(angles_no_mirror))
	sxprint(angles_no_mirror)
	"""






















































































































































































































































































"""39
	lina = numpy.argsort(radius_array)
	sorted_radius = radius_array[lina[::-1]]
	array_x = numpy.arange(sorted_radius.shape[0])
	angles_no_mirror = angles_no_mirror[lina[::-1]]
	nonzero_mask = list(nonzero_mask[0][lina[::-1]])

	"""

















"""40
	sxprint(array_x)
	sxprint(sorted_radius)
	sxprint(len(angles_no_mirror))
	sxprint(angles_no_mirror)
	"""






















































































































































































































